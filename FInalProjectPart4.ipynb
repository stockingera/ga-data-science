{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import scipy as scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Annmarie/ga-data-science\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## import all the files we will need\n",
    "## import all the files we will need\n",
    "test = pd.read_csv('./orange_small_test/orange_small_test.data',header=0,delimiter='\\t')\n",
    "train = pd.read_csv(\"cleanData\",sep = \",\", dtype = 'float32')\n",
    "labels= pd.read_csv('./orange_small_train_appetency.labels.txt',dtype = 'float32', header=-1 ,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnNames = test.columns\n",
    "\n",
    "goodColumns1 = columnNames[:188].tolist()\n",
    "goodColumns1.append( columnNames[230] )\n",
    "\n",
    "dftNew = test[goodColumns1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var1        688\n",
       "Var2       1284\n",
       "Var3       1282\n",
       "Var4       1638\n",
       "Var5       1506\n",
       "Var6      44391\n",
       "Var7      44377\n",
       "Var8          0\n",
       "Var9        688\n",
       "Var10      1506\n",
       "Var11      1282\n",
       "Var12       565\n",
       "Var13     44377\n",
       "Var14      1282\n",
       "Var15         0\n",
       "Var16      1506\n",
       "Var17      1638\n",
       "Var18      1638\n",
       "Var19      1638\n",
       "Var20         0\n",
       "Var21     44391\n",
       "Var22     44884\n",
       "Var23      1506\n",
       "Var24     42761\n",
       "Var25     44884\n",
       "Var26      1506\n",
       "Var27      1506\n",
       "Var28     44881\n",
       "Var29       688\n",
       "Var30       688\n",
       "          ...  \n",
       "Var202    50000\n",
       "Var203    49855\n",
       "Var204    50000\n",
       "Var205    48057\n",
       "Var206    44391\n",
       "Var207    50000\n",
       "Var208    49855\n",
       "Var209        0\n",
       "Var210    50000\n",
       "Var211    50000\n",
       "Var212    50000\n",
       "Var213     1142\n",
       "Var214    24712\n",
       "Var215      682\n",
       "Var216    50000\n",
       "Var217    49343\n",
       "Var218    49343\n",
       "Var219    44737\n",
       "Var220    50000\n",
       "Var221    50000\n",
       "Var222    50000\n",
       "Var223    44737\n",
       "Var224      855\n",
       "Var225    23981\n",
       "Var226    50000\n",
       "Var227    50000\n",
       "Var228    50000\n",
       "Var229    21568\n",
       "Var230        0\n",
       "label     50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Annmarie/anaconda/lib/python2.7/site-packages/pandas/core/generic.py:3178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "## Fill NaN values with the mean value of the column in order to prep the data for modeling \n",
    "for columnName in dftNew.columns:\n",
    "    mean = dftNew[columnName].mean()\n",
    "    dftNew[columnName].fillna(mean,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var1      50000\n",
       "Var2      50000\n",
       "Var3      50000\n",
       "Var4      50000\n",
       "Var5      50000\n",
       "Var6      50000\n",
       "Var7      50000\n",
       "Var8          0\n",
       "Var9      50000\n",
       "Var10     50000\n",
       "Var11     50000\n",
       "Var12     50000\n",
       "Var13     50000\n",
       "Var14     50000\n",
       "Var15         0\n",
       "Var16     50000\n",
       "Var17     50000\n",
       "Var18     50000\n",
       "Var19     50000\n",
       "Var20         0\n",
       "Var21     50000\n",
       "Var22     50000\n",
       "Var23     50000\n",
       "Var24     50000\n",
       "Var25     50000\n",
       "Var26     50000\n",
       "Var27     50000\n",
       "Var28     50000\n",
       "Var29     50000\n",
       "Var30     50000\n",
       "          ...  \n",
       "Var160    50000\n",
       "Var161    50000\n",
       "Var162    50000\n",
       "Var163    50000\n",
       "Var164    50000\n",
       "Var165    50000\n",
       "Var166    50000\n",
       "Var167        0\n",
       "Var168    50000\n",
       "Var169        0\n",
       "Var170    50000\n",
       "Var171    50000\n",
       "Var172    50000\n",
       "Var173    50000\n",
       "Var174    50000\n",
       "Var175        0\n",
       "Var176    50000\n",
       "Var177    50000\n",
       "Var178    50000\n",
       "Var179    50000\n",
       "Var180    50000\n",
       "Var181    50000\n",
       "Var182    50000\n",
       "Var183    50000\n",
       "Var184    50000\n",
       "Var185        0\n",
       "Var186    50000\n",
       "Var187    50000\n",
       "Var188    50000\n",
       "label     50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftNew.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Annmarie/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "dftNew.dropna(inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftNew.to_csv(\"cleanTestData\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##change datatype\n",
    "\n",
    "finaltDf = pd.read_csv(\"cleanTestData\",sep = \",\", dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var179</th>\n",
       "      <th>Var180</th>\n",
       "      <th>Var181</th>\n",
       "      <th>Var182</th>\n",
       "      <th>Var183</th>\n",
       "      <th>Var184</th>\n",
       "      <th>Var186</th>\n",
       "      <th>Var187</th>\n",
       "      <th>Var188</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.767442</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>404.131836</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>224088.65625</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.80814</td>\n",
       "      <td>360282.6875</td>\n",
       "      <td>8.586583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19475</td>\n",
       "      <td>3695632.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1476623.625</td>\n",
       "      <td>73787.609375</td>\n",
       "      <td>10.221184</td>\n",
       "      <td>2.860465</td>\n",
       "      <td>13.110465</td>\n",
       "      <td>165.1586</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.767442</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>404.131836</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>224088.65625</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.80814</td>\n",
       "      <td>360282.6875</td>\n",
       "      <td>8.586583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19475</td>\n",
       "      <td>3695632.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1476623.625</td>\n",
       "      <td>73787.609375</td>\n",
       "      <td>10.221184</td>\n",
       "      <td>2.860465</td>\n",
       "      <td>13.110465</td>\n",
       "      <td>165.1586</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.767442</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>404.131836</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>224088.65625</td>\n",
       "      <td>861.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.80814</td>\n",
       "      <td>360282.6875</td>\n",
       "      <td>8.586583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19475</td>\n",
       "      <td>3695632.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1476623.625</td>\n",
       "      <td>73787.609375</td>\n",
       "      <td>10.221184</td>\n",
       "      <td>2.860465</td>\n",
       "      <td>13.110465</td>\n",
       "      <td>165.1586</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.767442</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>404.131836</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>224088.65625</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.80814</td>\n",
       "      <td>360282.6875</td>\n",
       "      <td>8.586583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19475</td>\n",
       "      <td>3695632.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1476623.625</td>\n",
       "      <td>73787.609375</td>\n",
       "      <td>10.221184</td>\n",
       "      <td>2.860465</td>\n",
       "      <td>13.110465</td>\n",
       "      <td>165.1586</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.767442</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>404.131836</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>224088.65625</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.80814</td>\n",
       "      <td>360282.6875</td>\n",
       "      <td>8.586583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19475</td>\n",
       "      <td>3695632.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1476623.625</td>\n",
       "      <td>73787.609375</td>\n",
       "      <td>10.221184</td>\n",
       "      <td>2.860465</td>\n",
       "      <td>13.110465</td>\n",
       "      <td>165.1586</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Var1      Var2        Var3      Var4          Var5    Var6  Var7  \\\n",
       "0  11.767442  0.015576  404.131836  0.126374  224088.65625  1225.0   7.0   \n",
       "1  11.767442  0.015576  404.131836  0.126374  224088.65625   259.0   0.0   \n",
       "2  11.767442  0.015576  404.131836  0.126374  224088.65625   861.0  14.0   \n",
       "3  11.767442  0.015576  404.131836  0.126374  224088.65625  1568.0   7.0   \n",
       "4  11.767442  0.015576  404.131836  0.126374  224088.65625  1197.0   7.0   \n",
       "\n",
       "       Var9        Var10     Var11  ...     Var179     Var180  Var181  \\\n",
       "0  43.80814  360282.6875  8.586583  ...    2.19475  3695632.5     0.0   \n",
       "1  43.80814  360282.6875  8.586583  ...    2.19475  3695632.5     0.0   \n",
       "2  43.80814  360282.6875  8.586583  ...    2.19475  3695632.5     0.0   \n",
       "3  43.80814  360282.6875  8.586583  ...    2.19475  3695632.5     0.0   \n",
       "4  43.80814  360282.6875  8.586583  ...    2.19475  3695632.5     0.0   \n",
       "\n",
       "        Var182        Var183     Var184    Var186     Var187    Var188  label  \n",
       "0  1476623.625  73787.609375  10.221184  2.860465  13.110465  165.1586   -1.0  \n",
       "1  1476623.625  73787.609375  10.221184  2.860465  13.110465  165.1586   -1.0  \n",
       "2  1476623.625  73787.609375  10.221184  2.860465  13.110465  165.1586   -1.0  \n",
       "3  1476623.625  73787.609375  10.221184  2.860465  13.110465  165.1586   -1.0  \n",
       "4  1476623.625  73787.609375  10.221184  2.860465  13.110465  165.1586   -1.0  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var1      float32\n",
       "Var2      float32\n",
       "Var3      float32\n",
       "Var4      float32\n",
       "Var5      float32\n",
       "Var6      float32\n",
       "Var7      float32\n",
       "Var9      float32\n",
       "Var10     float32\n",
       "Var11     float32\n",
       "Var12     float32\n",
       "Var13     float32\n",
       "Var14     float32\n",
       "Var16     float32\n",
       "Var17     float32\n",
       "Var18     float32\n",
       "Var19     float32\n",
       "Var21     float32\n",
       "Var22     float32\n",
       "Var23     float32\n",
       "Var24     float32\n",
       "Var25     float32\n",
       "Var26     float32\n",
       "Var27     float32\n",
       "Var28     float32\n",
       "Var29     float32\n",
       "Var30     float32\n",
       "Var33     float32\n",
       "Var34     float32\n",
       "Var35     float32\n",
       "           ...   \n",
       "Var156    float32\n",
       "Var157    float32\n",
       "Var158    float32\n",
       "Var159    float32\n",
       "Var160    float32\n",
       "Var161    float32\n",
       "Var162    float32\n",
       "Var163    float32\n",
       "Var164    float32\n",
       "Var165    float32\n",
       "Var166    float32\n",
       "Var168    float32\n",
       "Var170    float32\n",
       "Var171    float32\n",
       "Var172    float32\n",
       "Var173    float32\n",
       "Var174    float32\n",
       "Var176    float32\n",
       "Var177    float32\n",
       "Var178    float32\n",
       "Var179    float32\n",
       "Var180    float32\n",
       "Var181    float32\n",
       "Var182    float32\n",
       "Var183    float32\n",
       "Var184    float32\n",
       "Var186    float32\n",
       "Var187    float32\n",
       "Var188    float32\n",
       "label     float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltDf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Analysis_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point all of the data has been preprocessed and is clean. Both finalDf and finaltDf have been cleaned and prepared for analysis. In the following portion of the notebook I will do my analysis using both the sklearn random forest model and the xgboosted random forest model. To create an unbias analysis of the models I will be using the AUC or area under the curve to measure the strength of each model in comparison to the other. For simplicity I will be reimporting the clean csvs and libraries below. While redundant this should make the code cleaner and easier to read than the above preprocessing and checking. To view the preprocessing of finalDf please access FinalProjectPart3 which is saved to this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from __future__ import division\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import scipy as scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn import metrics\n",
    "import graphviz as graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "test = pd.read_csv(\"cleanTestData\",sep = \",\", dtype = 'float32')\n",
    "train = pd.read_csv(\"cleanData\",sep = \",\", dtype = 'float32')\n",
    "\n",
    "colsRes = ['label']\n",
    "X = train.drop('label', axis=1)\n",
    "y = np.asarray(train['label'], dtype=\"|S6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from os import system \n",
    "def build_tree_image(model):\n",
    "    dotfile = open(\"tree.dot\", 'w')\n",
    "    export_graphviz(model,out_file = dotfile, feature_names = X.columns)\n",
    "    dotfile.close()\n",
    "    system(\"dot -Tpng tree.dot -o tree.png\")\n",
    "    \n",
    "build_tree_image(model)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = X.columns\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "features_df.sort('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Checkpoint_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the decision tree classifier we can see that feature Var 113 is the feature with the highest importance score. Lets move forward and change some parameters and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "                max_depth = 5,\n",
    "                min_samples_leaf = 7)\n",
    "\n",
    "model.fit(X, y)\n",
    "build_tree_image(model)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from os import system \n",
    "def build_tree_image(model):\n",
    "    dotfile = open(\"tree2.dot\", 'w')\n",
    "    export_graphviz(model,out_file = dotfile, feature_names = X.columns)\n",
    "    dotfile.close()\n",
    "    system(\"dot -Tpng tree2.dot -o tree2.png\")\n",
    "    \n",
    "build_tree_image(model)\n",
    "\n",
    "features = X.columns\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "features_df.sort('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Checkpoint_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I tuned the model to limit the depth of the tree. After doing this we can see that our feature importance scores changed drastically but we also have much more significant importance values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###lets attempt a gradient boosted tree\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "y_train = labels \n",
    "features = list(train.columns[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from matplotlib import pylab as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "def ceate_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()\n",
    "\n",
    "def get_data():\n",
    "\n",
    "    features = list(train.columns[2:])\n",
    "\n",
    "   \n",
    "\n",
    "    for feat in train.select_dtypes(include=['object']).columns:\n",
    "        m = train.groupby([feat])['label'].mean()\n",
    "        train[feat].replace(m,inplace=True)\n",
    "\n",
    "    x_train = train[features]\n",
    "\n",
    "    return features, x_train, y_train\n",
    "\n",
    "\n",
    "features, x_train, y_train = get_data()\n",
    "ceate_feature_map(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_params = {\"objective\": \"reg:linear\", \"eta\": 0.01, \"max_depth\": 5, \"seed\": 40, \"silent\": 1}\n",
    "num_rounds = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "gbdt = xgb.train(xgb_params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance = gbdt.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "plt.figure()\n",
    "df.plot()\n",
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(60, 100))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "plt.gcf().savefig('feature_importance_xgb.png')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "def ceate_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()\n",
    "\n",
    "def get_data():\n",
    "\n",
    "    features = list(train.columns[2:])\n",
    "\n",
    "   \n",
    "\n",
    "    for feat in train.select_dtypes(include=['object']).columns:\n",
    "        m = train.groupby([feat])['label'].mean()\n",
    "        train[feat].replace(m,inplace=True)\n",
    "\n",
    "    x_train = train[features]\n",
    "\n",
    "    return features, x_train, y_train\n",
    "\n",
    "\n",
    "features, x_train, y_train = get_data()\n",
    "ceate_feature_map(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\"objective\": \"reg:linear\", \"eta\": 0.01, \"max_depth\": 20, \"seed\": 50, \"silent\": 1}\n",
    "num_rounds = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "gbdt = xgb.train(xgb_params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = gbdt.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "plt.figure()\n",
    "df.plot()\n",
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "plt.gcf().savefig('feature_importance_xgb.png')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
